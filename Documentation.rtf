{\rtf1\ansi\ansicpg1252\cocoartf2761
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\margl1440\margr1440\vieww11520\viewh8400\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs24 \cf0 BUSINESS PROBLEM\
Consumers spend a lot of time figuring out what grocery store to go to for what items and struggle to know where they can get the best deals. This is because shoppers don\'92t have the tools to be able to compare prices of different grocery stores across on platform.\
\
EXECUTIVE SUMMARY\
Backend pulls grocery data from different websites and puts all that data into a singular database. The frontend of the application allows users to input what grocery items they want, and the backend calculates the total cost of all the goods at each of the stores. The deliverable to the user is a screen showing what store they should shop at, how much their goods collectively cost at that store, and a breakdown of how much each good costs at the store (they see a \'93receipt\'94).\
\
TECHNICAL SPECS\
The overall flow for GroceryPlugg is broken into two parts: a backend that initially scrapes data & uploads the data to a MySQL DB, and a frontend using Unity that allows for user input and interacts with said DB.\
\
BACKEND\
Each Aldi.py, ralphs.py, target.py scrapes the respective websites for groceries using Selenium/BeautifulSoup.\
\
dbOperations.py allows me to interact with the MySQL DB directly while I\'92m scraping.\
\
createTables.py is run periodically to create tables as I need them (if I want to expand to more stores, etc.).\
\
grocery_list.py defines a predefined list of grocery keywords that are used to scrape the different websites.\
\
*.html files are for debugging purposes, these are all the html files that failed to scrape from Target. I kept them in my directory for debugging purposes so I can analyze them and see why my scraper failed.\
\
FRONTEND\
Built with Unity which has a C# backend that connects to the MySQL DB. The frontend has three main pages (called panels in Unity) corresponding to a main landing page, an intermediate page where users can examine their cart, and a final results page showing the final cost.\
\
As users enter text into the text entry field, it autocompletes to our set of predefined so that users know what we do/don\'92t have. When the user hits the \'93checkout\'94 button, the main logic running behind the scenes is found in \'93OnCheckOut.cs\'94 which calls the method \'93public void CheckOut\'94. CheckOut parses the user-inputted data into a list of strings and then calls this SQL line "SELECT instanceName, price FROM \{tableName\} WHERE grocery = '\{grocery\}' ORDER BY price LIMIT 1\'94; for each of the user\'92s inputted groceries. So if we run this SQL line a bunch of times we get something like \'93joe\'92s eggs, 2.99\'94, \'93sam\'92s bacon, 4.99\'94 so my code stores all this information into a list for each of my tables (target, Ralphs, Aldi) and then loops through the list and adds up all the prices to get a total price. Whichever store has the lowest total price gets displayed in the final output.\
\
DB IMPLEMENTATION\
There are three tables each for a grocery store with columns grocery, instanceName, price, and lastModified. \
\
RUN FROM START TO FINISH\
All of the backend work is abstracted so the user doesn\'92t need to mess with any database accessing on their end. In order to run my application, simply use the interface as indicated - enter in goods to search for, and hit checkout, and the resulting page output will be the store with the cheapest goods.\
\
PROBLEMS/BLOCKERS\
Scraping data. This was really difficult because although the flow for scraping data was the same across each website (Selenium open browser + grab HTML -> BeautifulSoup parse HTML and extract meaningful data -> Insert data into DB), I ran into many challenges since each website\'92s HTML is ordered differently and the websites had different levels of bot detection etc. So scraping data was a big pain.\
\
Linking up MySQL/C#\
To use a MySQL DB with Unity is pretty complicated (at least for me). I had to install a .dll and put it into my project. This took me forever to figure out.\
\
WHO DID WHAT\
I did all of the coding (Jacob)\
Ziggy did the ER diagram + presentation\
Zach & Ethan cleaned some of our data\
\
\
}